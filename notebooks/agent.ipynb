{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig, AutomaticFunctionCallingConfig\n",
    "import os\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0ceb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_GENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8815dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a given city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city.\n",
    "    Returns:\n",
    "        str: A string describing the current weather.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Complex logic to get real weather data would go here.\n",
    "    # This includes:\n",
    "    # - Constructing the API request\n",
    "    # - Managing credentials and authentication\n",
    "    # - Calling a weather API\n",
    "    # - Handling errors and edge cases\n",
    "    # - Parsing the response\n",
    "\n",
    "    return f\"The current weather in {city} is sunny with a temperature of 25¬∞C.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7861bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    config=GenerateContentConfig(\n",
    "        tools=[get_weather], \n",
    "        automatic_function_calling=AutomaticFunctionCallingConfig(disable=False)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc037501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Goodbye! üëã\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "        user_message = input(\"You: \").strip()\n",
    "\n",
    "        if user_message.lower() in {\"exit\", \"quit\"}:\n",
    "            print(\"Agent: Goodbye! üëã\")\n",
    "            break\n",
    "\n",
    "        if not user_message:\n",
    "            continue\n",
    "\n",
    "        # `chat.send_message`:\n",
    "        # - Automatically appends your message to the chat history.\n",
    "        # - Sends the whole conversation to Gemini.\n",
    "        # - Returns the model's response as a Python object.\n",
    "        try:\n",
    "            response = chat.send_message(message=user_message)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error talking to Gemini: {e}\")\n",
    "            continue\n",
    "\n",
    "        # `response.text` is a convenience property that:\n",
    "        # - Concatenates all text parts of the model's reply.\n",
    "        # - Gives you a single plain string you can print.\n",
    "        agent_reply = response.text\n",
    "\n",
    "        print(f\"User: {user_message}\\n\")\n",
    "        print(f\"Agent: {agent_reply}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDS2-presentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
