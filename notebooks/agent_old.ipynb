{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc23cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig, Tool, Part, Content\n",
    "import os\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a1f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_GENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954e472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a given city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city.\n",
    "    Returns:\n",
    "        str: A string describing the current weather.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Complex logic to get real weather data would go here.\n",
    "    # This includes:\n",
    "    # - Constructing the API request\n",
    "    # - Managing credentials and authentication\n",
    "    # - Calling a weather API\n",
    "    # - Handling errors and edge cases\n",
    "    # - Parsing the response\n",
    "\n",
    "    return f\"The current weather in {city} is sunny with a temperature of 25¬∞C.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1aa834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function declaration for the model\n",
    "get_weather_function = {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Gets the current weather for a specified city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the city to get the weather for.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"city\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f378d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = Tool(function_declarations=[get_weather_function])\n",
    "config = GenerateContentConfig(tools=[tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Error talking to Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\nPlease retry in 30.697623311s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}\n",
      "‚ö†Ô∏è  Error talking to Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\nPlease retry in 15.979076039s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}\n",
      "‚ö†Ô∏è  Error talking to Gemini: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\nPlease retry in 13.634790418s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_message = input(\"You: \").strip()\n",
    "\n",
    "    if user_message.lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"Agent: Goodbye! üëã\")\n",
    "        break\n",
    "\n",
    "    if not user_message:\n",
    "        continue\n",
    "\n",
    "    # Define user prompt\n",
    "    contents = [\n",
    "        Content(\n",
    "            role=\"user\",\n",
    "            parts=[Part(text=user_message)],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=config,\n",
    "            contents=contents,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error talking to Gemini: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Check if the model wants to call a function\n",
    "    if response.candidates[0].content.parts[0].function_call:\n",
    "        tool_call = response.candidates[0].content.parts[0].function_call\n",
    "        print(f\"Function to call: {tool_call.name}\")\n",
    "        print(f\"Arguments: {tool_call.args}\")\n",
    "\n",
    "        # Here we would parse the arguments and call the actual function\n",
    "        if tool_call.name == \"get_weather\":\n",
    "            weather_info = get_weather(**tool_call.args)\n",
    "\n",
    "            function_response_part = Part.from_function_response(\n",
    "                name=tool_call.name,\n",
    "                response={\"result\": weather_info},\n",
    "            )\n",
    "\n",
    "            contents.append(response.candidates[0].content)\n",
    "            contents.append(Content(role=\"user\", parts=[function_response_part]))\n",
    "\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                config=config,\n",
    "                contents=contents,\n",
    "            )\n",
    "\n",
    "    agent_reply = response.candidates[0].content.parts[0].text\n",
    "\n",
    "    print(f\"User: {user_message}\\n\")\n",
    "    print(f\"Agent: {agent_reply}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDS2-presentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
